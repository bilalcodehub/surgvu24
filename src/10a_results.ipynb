{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f8161b-dffe-4058-8871-0423b4808b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 models for ensemble.\n",
      "Loaded model regnety_008 (1/3) from models/baseline/regnety_008.pkl.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model convnextv2_tiny (2/3) from models/baseline/convnextv2_tiny.pkl.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model vit_tiny (3/3) from models/baseline/vit_tiny.pkl.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Model  Accuracy  Precision    Recall  F1 Score   Time (s)\n",
      "0            regnety_008  0.584119   0.675336  0.512029  0.540557  74.195408\n",
      "1        convnextv2_tiny  0.818238   0.828582  0.704525  0.746908  78.108038\n",
      "2               vit_tiny  0.811633   0.786008  0.755999  0.768067  67.449265\n",
      "3               Ensemble  0.812745   0.832694  0.715647  0.755712   0.000802\n",
      "4  Prediction Correction  0.834749   0.879821  0.724274  0.767982   0.089151\n",
      "Results table saved to /home/exsdatalab/data/surgvu24/results_table.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------- IMPORT NECESSARY LIBRARIES ---------------------\n",
    "from fastai.vision.all import *\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# --------------------- DEFINE REQUIRED FUNCTIONS ---------------------\n",
    "\n",
    "def get_image(r): \n",
    "    \"\"\"\n",
    "    Constructs the full image path for a given row in the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        r (pd.Series): A row from the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        str: Full path to the image file.\n",
    "    \"\"\"\n",
    "    return str(dataroot_path / 'frames' / f\"{r['filename']}.jpg\")\n",
    "\n",
    "def smooth_predictions_with_neighbors(predicted_classes: List[str], window_size: int = 1) -> List[str]:\n",
    "    \"\"\"\n",
    "    Smooths the predicted class labels by exploring the neighboring frames.\n",
    "    \n",
    "    Args:\n",
    "        predicted_classes (List[str]): The list of predicted class labels per frame.\n",
    "        window_size (int): Number of neighboring frames to consider on each side for smoothing.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: The smoothed list of predicted class labels.\n",
    "    \"\"\"\n",
    "    if not predicted_classes:\n",
    "        return []\n",
    "    \n",
    "    num_frames = len(predicted_classes)\n",
    "    smoothed_predictions = []\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        # Define the window boundaries\n",
    "        start_idx = max(0, i - window_size)\n",
    "        end_idx = min(num_frames - 1, i + window_size)\n",
    "    \n",
    "        # Extract the neighborhood labels\n",
    "        neighborhood = predicted_classes[start_idx:end_idx + 1]\n",
    "    \n",
    "        # Count the frequency of each label in the neighborhood\n",
    "        label_counts = {}\n",
    "        for label in neighborhood:\n",
    "            label_counts[label] = label_counts.get(label, 0) + 1\n",
    "    \n",
    "        # Identify the most common label(s)\n",
    "        max_count = max(label_counts.values())\n",
    "        common_labels = [label for label, count in label_counts.items() if count == max_count]\n",
    "    \n",
    "        # Resolve ties by retaining the current frame's label\n",
    "        if len(common_labels) == 1:\n",
    "            most_common_label = common_labels[0]\n",
    "        else:\n",
    "            most_common_label = predicted_classes[i]\n",
    "    \n",
    "        smoothed_predictions.append(most_common_label)\n",
    "    \n",
    "    return smoothed_predictions\n",
    "\n",
    "def decode_predictions(preds: torch.Tensor, vocab: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Convert raw predictions into class labels.\n",
    "    \n",
    "    Args:\n",
    "        preds (torch.Tensor): Raw predictions (logits or probabilities).\n",
    "        vocab (List[str]): List of class labels.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: List of predicted class labels.\n",
    "    \"\"\"\n",
    "    pred_indices = preds.argmax(dim=1)\n",
    "    predicted_classes = [vocab[i] for i in pred_indices]\n",
    "    return predicted_classes\n",
    "\n",
    "# --------------------- DATA PREPARATION ---------------------\n",
    "\n",
    "# Define your data root path\n",
    "dataroot_path = Path('/home/exsdatalab/data/surgvu24')\n",
    "\n",
    "# Load the images DataFrame\n",
    "images_df = pd.read_csv(dataroot_path / 'final_labels.csv')\n",
    "\n",
    "# Get all model paths with '.pkl' extension in 'models/baseline/' directory\n",
    "models_path = [pth for pth in Path('models/baseline/').ls() if pth.suffix == '.pkl']\n",
    "\n",
    "# Check if models are found\n",
    "if not models_path:\n",
    "    raise ValueError(\"No models found in 'models/baseline/' directory with '.pkl' extension.\")\n",
    "\n",
    "print(f\"Found {len(models_path)} models for ensemble.\")\n",
    "\n",
    "# Filter validation data\n",
    "images_df_valid = images_df[images_df['valid'] == True].copy()\n",
    "\n",
    "# Construct image paths\n",
    "images_df_valid['image_path'] = images_df_valid.apply(get_image, axis=1)\n",
    "image_files = images_df_valid['image_path'].tolist()\n",
    "true_labels = images_df_valid['task_label'].tolist()\n",
    "\n",
    "# Ensure image files exist\n",
    "image_files = [Path(p) for p in image_files if Path(p).exists()]\n",
    "if not image_files:\n",
    "    raise ValueError(\"No valid image files found for validation.\")\n",
    "\n",
    "# --------------------- MODEL PREDICTIONS ---------------------\n",
    "\n",
    "# Store predicted labels, raw predictions, and computation times for each model\n",
    "all_model_preds = []\n",
    "all_raw_preds = []\n",
    "model_times = []\n",
    "vocab = None  # To store vocabulary from the first model\n",
    "\n",
    "for idx, model_path in enumerate(models_path):\n",
    "    model_name = model_path.stem  # Get model filename without extension\n",
    "\n",
    "    # Load the model\n",
    "    try:\n",
    "        learner = load_learner(model_path, cpu=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model at {model_path}: {e}\")\n",
    "        continue\n",
    "    print(f'Loaded model {model_name} ({idx+1}/{len(models_path)}) from {model_path}.')\n",
    "\n",
    "    # Create test_dl using the loaded learner's DataLoaders\n",
    "    test_dl = learner.dls.test_dl(image_files, bs=128, num_workers=8)\n",
    "\n",
    "    # Get predictions from the model\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            raw_preds, _ = learner.get_preds(dl=test_dl)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        preds = decode_predictions(raw_preds.cpu(), learner.dls.vocab)\n",
    "        all_model_preds.append({'model_name': model_name, 'preds': preds, 'raw_preds': raw_preds.cpu()})\n",
    "        all_raw_preds.append(raw_preds.cpu())  # Store raw predictions for ensemble\n",
    "        model_times.append({'model_name': model_name, 'time': elapsed_time})\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction with model at {model_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Store vocab from the first model\n",
    "    if vocab is None:\n",
    "        vocab = learner.dls.vocab\n",
    "\n",
    "    # Free up memory\n",
    "    del learner\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "if not all_raw_preds:\n",
    "    raise ValueError(\"No predictions were made. Please check your models and image paths.\")\n",
    "\n",
    "# --------------------- ENSEMBLE PREDICTIONS ---------------------\n",
    "\n",
    "# Measure time for ensemble prediction\n",
    "ensemble_start_time = time.time()\n",
    "\n",
    "# Average the raw predictions across all models\n",
    "ensemble_raw_preds = torch.stack(all_raw_preds).mean(0)\n",
    "\n",
    "ensemble_end_time = time.time()\n",
    "ensemble_elapsed_time = ensemble_end_time - ensemble_start_time\n",
    "\n",
    "ensemble_preds = decode_predictions(ensemble_raw_preds, vocab)\n",
    "\n",
    "# --------------------- POST-PROCESSING ---------------------\n",
    "\n",
    "# Measure time for post-processing (prediction correction)\n",
    "best_avg_ws = 8  # As defined earlier or determined through evaluation\n",
    "postproc_start_time = time.time()\n",
    "smoothed_preds = smooth_predictions_with_neighbors(ensemble_preds, window_size=best_avg_ws)\n",
    "postproc_end_time = time.time()\n",
    "postproc_elapsed_time = postproc_end_time - postproc_start_time\n",
    "\n",
    "# --------------------- METRICS CALCULATION ---------------------\n",
    "\n",
    "# Map labels to indices\n",
    "label_to_idx = {label: idx for idx, label in enumerate(vocab)}\n",
    "true_indices = [label_to_idx[label] for label in true_labels]\n",
    "\n",
    "# Initialize a list to store metrics for each model\n",
    "metrics_list = []\n",
    "\n",
    "# Compute metrics for each model\n",
    "for model_info in all_model_preds:\n",
    "    model_name = model_info['model_name']\n",
    "    preds = model_info['preds']\n",
    "    pred_indices = [label_to_idx[label] for label in preds]\n",
    "\n",
    "    acc = accuracy_score(true_indices, pred_indices)\n",
    "    prec = precision_score(true_indices, pred_indices, average='macro', zero_division=0)\n",
    "    rec = recall_score(true_indices, pred_indices, average='macro', zero_division=0)\n",
    "    f1 = f1_score(true_indices, pred_indices, average='macro', zero_division=0)\n",
    "\n",
    "    # Find the time taken for this model\n",
    "    model_time = next((item['time'] for item in model_times if item['model_name'] == model_name), None)\n",
    "\n",
    "    metrics_list.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1 Score': f1,\n",
    "        'Time (s)': model_time\n",
    "    })\n",
    "\n",
    "# Compute metrics for the ensemble\n",
    "ensemble_pred_indices = [label_to_idx[label] for label in ensemble_preds]\n",
    "\n",
    "acc = accuracy_score(true_indices, ensemble_pred_indices)\n",
    "prec = precision_score(true_indices, ensemble_pred_indices, average='macro', zero_division=0)\n",
    "rec = recall_score(true_indices, ensemble_pred_indices, average='macro', zero_division=0)\n",
    "f1 = f1_score(true_indices, ensemble_pred_indices, average='macro', zero_division=0)\n",
    "\n",
    "metrics_list.append({\n",
    "    'Model': 'Ensemble',\n",
    "    'Accuracy': acc,\n",
    "    'Precision': prec,\n",
    "    'Recall': rec,\n",
    "    'F1 Score': f1,\n",
    "    'Time (s)': ensemble_elapsed_time\n",
    "})\n",
    "\n",
    "# Compute metrics for the post-processed predictions\n",
    "smoothed_pred_indices = [label_to_idx[label] for label in smoothed_preds]\n",
    "\n",
    "acc = accuracy_score(true_indices, smoothed_pred_indices)\n",
    "prec = precision_score(true_indices, smoothed_pred_indices, average='macro', zero_division=0)\n",
    "rec = recall_score(true_indices, smoothed_pred_indices, average='macro', zero_division=0)\n",
    "f1 = f1_score(true_indices, smoothed_pred_indices, average='macro', zero_division=0)\n",
    "\n",
    "metrics_list.append({\n",
    "    'Model': 'Prediction Correction',\n",
    "    'Accuracy': acc,\n",
    "    'Precision': prec,\n",
    "    'Recall': rec,\n",
    "    'F1 Score': f1,\n",
    "    'Time (s)': postproc_elapsed_time\n",
    "})\n",
    "\n",
    "# Create a DataFrame from the metrics list\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Display the results table\n",
    "print(metrics_df)\n",
    "\n",
    "# Save the results table to a CSV file\n",
    "results_csv_path = dataroot_path / 'results_table.csv'\n",
    "metrics_df.to_csv(results_csv_path, index=False)\n",
    "print(f\"Results table saved to {results_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52bf5c6-32a7-427b-a4c7-fe879f9b6e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 models for ensemble.\n",
      "Loaded model regnety_008 (1/3) from models/baseline/regnety_008.pkl.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model convnextv2_tiny (2/3) from models/baseline/convnextv2_tiny.pkl.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model vit_tiny (3/3) from models/baseline/vit_tiny.pkl.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Model  Accuracy  Precision    Recall  F1 Score   Time (s)\n",
      "0            regnety_008  0.584119   0.675336  0.512029  0.540557  73.783131\n",
      "1        convnextv2_tiny  0.818238   0.828582  0.704525  0.746908  78.418473\n",
      "2               vit_tiny  0.811633   0.786008  0.755999  0.768067  67.497329\n",
      "3               Ensemble  0.812745   0.832694  0.715647  0.755712   0.000877\n",
      "4  Prediction Correction  0.834749   0.879821  0.724274  0.767982   0.089676\n",
      "Results table saved to /home/exsdatalab/data/surgvu24/results_table.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the results table to a CSV file\n",
    "results_csv_path = dataroot_path / 'results_table.csv'\n",
    "metrics_df.to_csv(results_csv_path, index=False)\n",
    "print(f\"Results table saved to {results_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0aa9bc-548d-495b-8410-c459db2f5240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
